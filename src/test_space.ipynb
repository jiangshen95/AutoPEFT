{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/autopeft/anaconda3/envs/autopeft/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/autopeft/anaconda3/envs/autopeft/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.15s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of label classes: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/autopeft/anaconda3/envs/autopeft/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence', 'label', 'idx'],\n",
      "    num_rows: 300\n",
      "}) Dataset({\n",
      "    features: ['sentence', 'label', 'idx'],\n",
      "    num_rows: 100\n",
      "})\n",
      "finished init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1: 100%|██████████| 19/19 [00:48<00:00,  2.58s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 || Validation loss: nan || Validation accuracy: 0.360000\n",
      "{'eval_loss': nan, 'eval_accuracy': 0.36}\n"
     ]
    }
   ],
   "source": [
    "from src.run_model import PEFTModel\n",
    "from src.peft_search_space import PEFTSearchSpace\n",
    "from src.dataset_wrapper import PEFTDataset\n",
    "from pruning_methods import prune_model\n",
    "from utils.gpu_memory_plot import get_free_gpu_memory\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import torch\n",
    "\n",
    "logger = logging.getLogger('controller')\n",
    "logger.setLevel(logging.INFO)  # 设置日志级别\n",
    "time_str = time.strftime('%Y-%m-%d_%H:%M:%S', time.localtime())\n",
    "day_str = time.strftime('%Y-%m-%d', time.localtime())\n",
    "output_dir = f'outputs/{day_str}'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "file_handler = logging.FileHandler(\n",
    "    f'outputs/{day_str}/output_{time_str}.log', mode='w')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "logger.info('Start loading dataset')\n",
    "dataset = PEFTDataset(\n",
    "    'glue', 'cola', test_size=100, train_size=300).get_dataset()\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lora', type=int, nargs='+')\n",
    "parser.add_argument('--adapter', type=int, nargs='+')\n",
    "parser.add_argument('--base_lora', type=int)\n",
    "parser.add_argument('--base_adapter', type=int)\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "searched_args = []\n",
    "searched_res = []\n",
    "\n",
    "# baseline\n",
    "logger.info('Start baseline')\n",
    "\n",
    "\n",
    "def wrapper(search_list, idt='lora'):\n",
    "    global model, res, configs, gradients, activations\n",
    "    args = parser.parse_args(args=[])\n",
    "    if idt == 'lora':\n",
    "        args.lora = search_list\n",
    "    elif idt == 'adapter':\n",
    "        args.adapter = search_list\n",
    "    args.epochs = 1\n",
    "    args.instructs = 1\n",
    "    configs = PEFTSearchSpace(args).get_config()\n",
    "    model = PEFTModel(configs, dataset).half()\n",
    "    res, gradients, activations = model.run()\n",
    "    logger.info(f'Result {res} for {search_list}')\n",
    "    model = None\n",
    "    gradients = None\n",
    "    activations = None\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def wrapper2(search_list, search_list2):\n",
    "    global model, res, configs, gradients, activations\n",
    "    args = parser.parse_args(args=[])\n",
    "    args.lora = search_list\n",
    "    args.adapter = search_list2\n",
    "    args.epochs = 1\n",
    "    args.instructs = 1\n",
    "    configs = PEFTSearchSpace(args).get_config()\n",
    "    model = PEFTModel(configs, dataset)\n",
    "    res, gradients, activations = model.run()\n",
    "    logger.info(f'Result for {search_list, search_list2}: {res}')\n",
    "\n",
    "\n",
    "# logger.info(\"Start adapter baseline\")\n",
    "# wrapper([32] * 16, 'adapter')\n",
    "\n",
    "# logger.info('Start lora baseline')\n",
    "# wrapper([32] * 32, 'lora')\n",
    "\n",
    "prune_turn = 10\n",
    "logger.info('-----Start gradient test------')\n",
    "\n",
    "origin_search_list = [32] * 32\n",
    "origin_search_list2 = [32] * 32\n",
    "search_list = deepcopy(origin_search_list)\n",
    "search_list2 = deepcopy(origin_search_list2)\n",
    "\n",
    "for _ in range(1):\n",
    "    model = None\n",
    "    torch.cuda.empty_cache()\n",
    "    logger.info(\n",
    "        f'Start searching for lora:{search_list} adapter:{search_list2}')\n",
    "    args.lora = search_list\n",
    "    args.adapter = search_list2\n",
    "    args.epochs = 1\n",
    "    configs = PEFTSearchSpace(args).get_config()\n",
    "    model = PEFTModel(configs, dataset).half()\n",
    "    res, gradients, activations = model.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "\n",
    "dataset_train=datasets.load_dataset('rotten_tomatoes',split=\"train[:100]\")\n",
    "dataset_test=datasets.load_dataset('rotten_tomatoes',split=\"test[:50%]\")\n",
    "dataset=datasets.DatasetDict({'train':dataset_train,'test':dataset_test})\n",
    "\n",
    "def add_prefix(example):\n",
    "    example[\"text\"] = 'This is an prefix' + example[\"text\"]\n",
    "    return example\n",
    "\n",
    "instructed_dataset=dataset.map(add_prefix)\n",
    "\n",
    "print(instructed_dataset)\n",
    "instructed_dataset['train']['text'][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pruning_methods import prune_model\n",
    "idx, idt = prune_model(\n",
    "    model.model,\n",
    "    task_name='my_module',\n",
    "    opts=['lora', 'adapter'],\n",
    "    p_method='gradient',\n",
    "    top_p=12,\n",
    "    print_names=True,\n",
    "    gradients=gradients)\n",
    "logger.info(f'Pruned layer: {idx, idt}')\n",
    "search_list[int(idx)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n",
      "422\n"
     ]
    }
   ],
   "source": [
    "params_need_record = [\n",
    "    param for name, param in model.model.named_parameters()\n",
    "    if param.requires_grad\n",
    "]\n",
    "print(len(params_need_record))\n",
    "print(len(list(model.model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(activations['module.model.layers.0.self_attn.q_proj.loras.my_module.lora_A'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autopeft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
