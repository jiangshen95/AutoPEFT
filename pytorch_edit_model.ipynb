{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个文件将使用pytorch修改模型结构，包括删除某个模块（group），以及修改瓶颈维度。首先通过运行第一个代码块准备好model和dataset，第一个代码块的代码来自lab_demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['heads.default.3.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\13061\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training epoch 1: 100%|██████████| 534/534 [00:22<00:00, 23.67batch/s]\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库和函数\n",
    "# 用于加载和处理序列到序列的语言模型\n",
    "import hiddenlayer as h\n",
    "import argparse\n",
    "import logging\n",
    "import re\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "# 导入必要的库\n",
    "from adapters import AdapterTrainer\n",
    "from transformers import TrainingArguments, EvalPrediction\n",
    "import numpy as np\n",
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaTokenizer\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from adapters import AutoAdapterModel, AdapterArguments, AdapterTrainer, AdapterConfig, ConfigUnion, LoRAConfig, SeqBnConfig, PrefixTuningConfig\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from pruning_methods import *\n",
    "# from roberta_train_demo import plot_small_value_ratios\n",
    "\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    logger.info(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Define global variables\n",
    "device = None\n",
    "dataset = None\n",
    "model = None\n",
    "tokenizer = None\n",
    "train_dataloader = None\n",
    "valid_dataloader = None\n",
    "optimizer = None\n",
    "scheduler = None\n",
    "loss_fn = None\n",
    "dummy_input = None\n",
    "\n",
    "\n",
    "def get_dataset(name):\n",
    "    global dataset, model\n",
    "    if name in ['axb', 'axg', 'cb', 'copa', 'multirc', 'record', 'rte', 'wic', 'wsc']:\n",
    "        dataset = load_dataset(\"super_glue\", name)\n",
    "    else:\n",
    "        dataset = load_dataset(name)\n",
    "    if dataset['test']:\n",
    "        # 获取分类信息\n",
    "        num_labels = dataset[\"test\"].features[\"label\"].num_classes\n",
    "        # 初始化分类头\n",
    "        model.add_classification_head(name, num_labels=num_labels)\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        logger.info(\"No test dataset available for this task.\")\n",
    "\n",
    "\n",
    "def preprocessing(task_name, configs=None):\n",
    "    global device, dataset, model, tokenizer, train_dataloader, valid_dataloader, optimizer, scheduler, loss_fn\n",
    "    logger.info(\"Start Preprocessing...\")\n",
    "    # 定义一些参数\n",
    "    model_name_or_path = \"roberta-base\"\n",
    "    output_dir = \"out/\"\n",
    "\n",
    "    # 检查是否有可用的GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 添加lora和adapter\n",
    "    # 加载预训练的序列到序列语言模型\n",
    "    model = AutoAdapterModel.from_pretrained(model_name_or_path)\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "    print_trainable_parameters(model)\n",
    "    # 加载数据集\n",
    "    get_dataset(task_name)\n",
    "\n",
    "    if configs == None:\n",
    "        # 配置PEFT的参数\n",
    "        lora_config = LoRAConfig(\n",
    "            r=32,  # 设置LoRA的rank\n",
    "            alpha=32,  # LoRA的alpha值，决定参数增加的数量\n",
    "            dropout=0.1,  # LoRA层的dropout比例\n",
    "            # leave_out=[6, 7, 8, 9, 10, 11],  # 指定需要转换的层 #important\n",
    "        )\n",
    "\n",
    "        bn_config = SeqBnConfig(\n",
    "            reduction_factor=16,  # 设置瓶颈维度\n",
    "            # leave_out=[6, 7, 8, 9, 10, 11]  # 指定需要转换的层 #important\n",
    "        )\n",
    "\n",
    "        config_list = [lora_config, bn_config]\n",
    "    else:\n",
    "        config_list = configs\n",
    "\n",
    "    peft_config = ConfigUnion(*[config_list[i]\n",
    "                              for i in range(len(config_list))])\n",
    "\n",
    "    model.add_adapter(task_name, peft_config)\n",
    "    model.train_adapter(task_name)\n",
    "    model.set_active_adapters(task_name)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    print_trainable_parameters(model)\n",
    "    if 'train' not in dataset:\n",
    "        dataset = dataset['test'].train_test_split(test_size=0.5)\n",
    "\n",
    "    # 定义训练和验证的数据加载器\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset['train'], batch_size=16, shuffle=True)\n",
    "    valid_dataloader = DataLoader(\n",
    "        dataset['test'], batch_size=16, shuffle=False)\n",
    "\n",
    "    # 定义优化器和学习率调度器\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-7)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 3)\n",
    "\n",
    "    # 定义损失函数\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    logger.info(\"Start training...\")\n",
    "\n",
    "\n",
    "def train_epoch(epoch_num):\n",
    "    global dummy_input\n",
    "    # 重置优化器\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 3)\n",
    "    # 开始训练\n",
    "    for epoch in range(epoch_num):\n",
    "        model.train()\n",
    "        for batch in tqdm(train_dataloader, desc=f\"Training epoch {epoch+1}\", unit=\"batch\"):\n",
    "            text_fields = [\n",
    "                field for field in dataset['test'].column_names if field not in ['label', 'idx']]\n",
    "            batch_fields = [batch[field] for field in text_fields]\n",
    "\n",
    "            inputs = tokenizer(*batch_fields,\n",
    "                               return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {name: tensor.to(device) for name,\n",
    "                      tensor in inputs.items()}  # 将输入数据移动到GPU上\n",
    "            batch['label'] = batch['label'].to(device)\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, batch['label'])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "        # 验证\n",
    "        model.eval()\n",
    "        total_loss, total_correct, total_count = 0, 0, len(\n",
    "            dataset['test'])\n",
    "        for batch in valid_dataloader:\n",
    "            with torch.no_grad():\n",
    "                text_fields = [\n",
    "                    field for field in dataset['test'].column_names if field not in ['label', 'idx']]\n",
    "                batch_fields = [batch[field] for field in text_fields]\n",
    "\n",
    "                inputs = tokenizer(*batch_fields,\n",
    "                                   return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "                inputs = {name: tensor.to(device) for name,\n",
    "                          tensor in inputs.items()}  # 将输入数据移动到GPU上\n",
    "                if (dummy_input == None):\n",
    "                    dummy_input = inputs\n",
    "                batch['label'] = batch['label'].to(device)\n",
    "                outputs = model(**inputs)\n",
    "                loss = loss_fn(outputs.logits, batch['label'])\n",
    "                total_loss += loss.item()\n",
    "                total_correct += (outputs.logits.argmax(dim=-1)\n",
    "                                  == batch['label']).sum().item()\n",
    "        logger.info(\n",
    "            f'Epoch {epoch+1} || Validation loss: {total_loss/total_count:.6f} || Validation accuracy: {total_correct/total_count:.6f}')\n",
    "\n",
    "\n",
    "def get_trainable_parameters(model):\n",
    "    names = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            # logger.info(name)\n",
    "            names.append(name)\n",
    "    return names\n",
    "\n",
    "\n",
    "def plot_small_value_ratios(groups, model):\n",
    "    group_names = []\n",
    "    small_value_ratios = []\n",
    "    for group, names in groups.items():\n",
    "        num_small_values = 0\n",
    "        total_values = 0\n",
    "        for name in names:\n",
    "            weights = model.state_dict()[name]\n",
    "            num_small_values += torch.lt(torch.abs(weights),\n",
    "                                         0.001).sum().item()\n",
    "            total_values += weights.numel()\n",
    "        small_value_ratios.append(num_small_values / total_values)\n",
    "        group_names.append(group)\n",
    "\n",
    "    plt.bar(group_names, small_value_ratios)\n",
    "    plt.xlabel('Group')\n",
    "    plt.ylabel('Ratio of small values')\n",
    "    plt.title('Ratio of weights less than 0.001 in each group')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_total_parameters(groups, model):\n",
    "    group_names = []\n",
    "    total_parameters = []\n",
    "    for group, names in groups.items():\n",
    "        total_values = 0\n",
    "        for name in names:\n",
    "            weights = model.state_dict()[name]\n",
    "            total_values += weights.numel()\n",
    "        total_parameters.append(total_values)\n",
    "        group_names.append(group)\n",
    "\n",
    "    plt.bar(group_names, total_parameters)\n",
    "    plt.xlabel('Group')\n",
    "    plt.ylabel('Total parameters')\n",
    "    plt.title('Total parameters in each group')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def set_weights_to_zero_and_untrainable(group, model):\n",
    "    for name in group:\n",
    "        # 获取权重\n",
    "        weights = model.state_dict()[name]\n",
    "        # 将权重设置为全 0\n",
    "        weights.zero_()\n",
    "        # 将修改后的权重重新赋值给模型中的对应模块\n",
    "\n",
    "        name = re.sub(r'\\.(\\d+)', r'[\\1]', name)\n",
    "        exec('model.'+name+'= Parameter(data=weights, requires_grad=False)')\n",
    "\n",
    "\n",
    "def reinitialize_trainable_parameters(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            if len(param.shape) == 1:  # bias\n",
    "                torch.nn.init.zeros_(param)\n",
    "            else:  # weights\n",
    "                torch.nn.init.xavier_uniform_(param)\n",
    "\n",
    "\n",
    "def main():\n",
    "    global model, dataset\n",
    "    parser = argparse.ArgumentParser(description='Lab demo script')\n",
    "    parser.add_argument('--run_baseline_lora', action='store_true',\n",
    "                        help='Run the baseline: lora or adapter')\n",
    "    parser.add_argument('--run_baseline_adapter', action='store_true',\n",
    "                        help='Run the baseline: lora or adapter')\n",
    "    parser.add_argument('--f')\n",
    "    args = parser.parse_args()\n",
    "    # 创建一个日志记录器\n",
    "    logger = logging.getLogger('lab')\n",
    "    logger.setLevel(logging.INFO)  # 设置日志级别\n",
    "\n",
    "    # 创建一个文件处理器，将日志写入到文件中\n",
    "    file_handler = logging.FileHandler('output.log', mode='w')\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # 创建一个格式器，定义日志的格式\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    # 将文件处理器添加到日志记录器中\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    task_names = ['axb']\n",
    "    task_names = ['rotten_tomatoes']\n",
    "    # task_names = ['axg', 'cb', 'copa',\n",
    "    #   'multirc', 'record', 'rte', 'wic', 'wsc']\n",
    "    # 配置PEFT的参数\n",
    "    lora_config = LoRAConfig(\n",
    "        r=64,  # 设置LoRA的rank\n",
    "        alpha=32,  # LoRA的alpha值，决定参数增加的数量\n",
    "        dropout=0.1,  # LoRA层的dropout比例\n",
    "        # leave_out=[6, 7, 8, 9, 10, 11],  # 指定需要转换的层 #important\n",
    "    )\n",
    "\n",
    "    bn_config = SeqBnConfig(\n",
    "        reduction_factor=16,  # 设置瓶颈维度\n",
    "        # leave_out=[6, 7, 8, 9, 10, 11]  # 指定需要转换的层 #important\n",
    "    )\n",
    "\n",
    "    configs = [lora_config, bn_config]\n",
    "\n",
    "    if args.run_baseline_lora:\n",
    "        for task in task_names:\n",
    "            preprocessing(task, [lora_config])\n",
    "            logger.info(f'Task:{task}')\n",
    "            train_epoch(10)\n",
    "    elif args.run_baseline_adapter:\n",
    "        for task in task_names:\n",
    "            model = None\n",
    "            dataset = None\n",
    "            preprocessing(task, [bn_config])\n",
    "            logger.info(f'Task:{task}')\n",
    "            train_epoch(10)\n",
    "    else:\n",
    "        for task in task_names:\n",
    "            model = None\n",
    "            dataset = None\n",
    "            preprocessing(task, configs)\n",
    "            torch.cuda.empty_cache()\n",
    "            logger.info(f'Task:{task}')\n",
    "            train_epoch(1)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13061\\AppData\\Roaming\\Python\\Python311\\site-packages\\adapters\\composition.py:242: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if tensor is not None and hidden_states.shape[0] >= tensor.shape[0]:\n",
      "C:\\Users\\13061\\AppData\\Roaming\\Python\\Python311\\site-packages\\adapters\\composition.py:253: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  max_bsz = max(query.shape[0], key.shape[0], value.shape[0])\n",
      "C:\\Users\\13061\\AppData\\Roaming\\Python\\Python311\\site-packages\\adapters\\composition.py:227: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if tensor is not None and hidden_states.shape[0] >= tensor.shape[0]:\n",
      "C:\\Users\\13061\\AppData\\Roaming\\Python\\Python311\\site-packages\\adapters\\methods\\adapter_layer_base.py:56: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if context.output_adapter_gating_scores:\n",
      "C:\\Users\\13061\\AppData\\Roaming\\Python\\Python311\\site-packages\\adapters\\context.py:125: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if getattr(ctx, \"output_\" + attr, False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'model.onnx' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网络可视化\n",
    "import netron\n",
    "model.to('cuda')\n",
    "torch.onnx.export(model, dummy_input, \"model.onnx\")\n",
    "netron.start('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 可视化输入，16*43,16=batch_size,43=sequence_length\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(dummy_input['input_ids'].cpu())\n",
    "plt.show()\n",
    "plt.imshow(dummy_input['attention_mask'].cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta.encoder.layer.0.attention.self.loras.': ['roberta.encoder.layer.0.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.0.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
       "  'roberta.encoder.layer.0.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.0.attention.self.value.loras.rotten_tomatoes.lora_B'],\n",
       " 'roberta.encoder.layer.1.attention.self.loras.': ['roberta.encoder.layer.1.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.1.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
       "  'roberta.encoder.layer.1.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.1.attention.self.value.loras.rotten_tomatoes.lora_B'],\n",
       " 'roberta.encoder.layer.2.attention.self.loras.': ['roberta.encoder.layer.2.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.2.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
       "  'roberta.encoder.layer.2.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.2.attention.self.value.loras.rotten_tomatoes.lora_B'],\n",
       " 'roberta.encoder.layer.3.attention.self.loras.': ['roberta.encoder.layer.3.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.3.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
       "  'roberta.encoder.layer.3.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.3.attention.self.value.loras.rotten_tomatoes.lora_B'],\n",
       " 'roberta.encoder.layer.4.attention.self.loras.': ['roberta.encoder.layer.4.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.4.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
       "  'roberta.encoder.layer.4.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.4.attention.self.value.loras.rotten_tomatoes.lora_B'],\n",
       " 'roberta.encoder.layer.5.attention.self.loras.': ['roberta.encoder.layer.5.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.5.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
       "  'roberta.encoder.layer.5.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.5.attention.self.value.loras.rotten_tomatoes.lora_B'],\n",
       " 'roberta.encoder.layer.6.attention.self.loras.': ['roberta.encoder.layer.6.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.6.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
       "  'roberta.encoder.layer.6.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.6.attention.self.value.loras.rotten_tomatoes.lora_B'],\n",
       " 'roberta.encoder.layer.7.attention.self.loras.': ['roberta.encoder.layer.7.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.7.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
       "  'roberta.encoder.layer.7.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.7.attention.self.value.loras.rotten_tomatoes.lora_B'],\n",
       " 'roberta.encoder.layer.8.attention.self.loras.': ['roberta.encoder.layer.8.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.8.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
       "  'roberta.encoder.layer.8.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.8.attention.self.value.loras.rotten_tomatoes.lora_B'],\n",
       " 'roberta.encoder.layer.9.attention.self.loras.': ['roberta.encoder.layer.9.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.9.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
       "  'roberta.encoder.layer.9.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.9.attention.self.value.loras.rotten_tomatoes.lora_B'],\n",
       " 'roberta.encoder.layer.10.attention.self.loras.': ['roberta.encoder.layer.10.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.10.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
       "  'roberta.encoder.layer.10.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.10.attention.self.value.loras.rotten_tomatoes.lora_B'],\n",
       " 'roberta.encoder.layer.11.attention.self.loras.': ['roberta.encoder.layer.11.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.11.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
       "  'roberta.encoder.layer.11.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
       "  'roberta.encoder.layer.11.attention.self.value.loras.rotten_tomatoes.lora_B']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=get_trainable_parameters(model)\n",
    "names\n",
    "groups=group_parameters_by_prefix(names,['lora'],print_names=True,task_name='rotten_tomatoes')\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'adapters.methods.lora.LoRA'>\n",
      "LoRA(\n",
      "  (lora_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "{'__module__': 'adapters.methods.lora', '__init__': <function LoRA.__init__ at 0x00000232CBCCBE20>, 'delta_w': <property object at 0x00000232CBCF10D0>, 'com': <function LoRA.com at 0x00000232CBCCBF60>, 'com_inv': <function LoRA.com_inv at 0x00000232CBCFC040>, 'forward': <function LoRA.forward at 0x00000232CBCFC0E0>, '__doc__': None}\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([[0.0509, 0.5631, 0.9166,  ..., 0.9808, 0.7993, 0.6711],\n",
      "        [0.0540, 0.4591, 0.4299,  ..., 0.7956, 0.9919, 0.5868],\n",
      "        [0.5079, 0.1537, 0.0531,  ..., 0.1103, 0.2454, 0.8384],\n",
      "        ...,\n",
      "        [0.5309, 0.1880, 0.6482,  ..., 0.4010, 0.6550, 0.8886],\n",
      "        [0.4712, 0.2487, 0.6008,  ..., 0.6447, 0.0079, 0.1125],\n",
      "        [0.2867, 0.7739, 0.2853,  ..., 0.3575, 0.0205, 0.5489]],\n",
      "       requires_grad=True)\n",
      "torch.Size([32, 768])\n"
     ]
    }
   ],
   "source": [
    "import adapters\n",
    "\n",
    "group = ['roberta.encoder.layer.0.attention.self.query.loras.rotten_tomatoes.lora_A',\n",
    "         'roberta.encoder.layer.0.attention.self.query.loras.rotten_tomatoes.lora_B',\n",
    "         'roberta.encoder.layer.0.attention.self.value.loras.rotten_tomatoes.lora_A',\n",
    "         'roberta.encoder.layer.0.attention.self.value.loras.rotten_tomatoes.lora_B']\n",
    "module_name = 'roberta.encoder.layer.0.attention.self.query.loras.rotten_tomatoes'\n",
    "name = re.sub(r'\\.(\\d+)', r'[\\1]', module_name)\n",
    "exec('module=model.'+name,\n",
    "     globals(), locals())\n",
    "print(type(module))\n",
    "print(module)\n",
    "print(adapters.methods.lora.LoRA.__dict__)\n",
    "\n",
    "module_name = 'roberta.encoder.layer.0.attention.self.query.loras.rotten_tomatoes.lora_A'\n",
    "name = re.sub(r'\\.(\\d+)', r'[\\1]', module_name)\n",
    "exec('module=model.'+name,\n",
    "     globals(), locals())\n",
    "print(type(module))\n",
    "print(module)\n",
    "print(module.size())\n",
    "\n",
    "name='roberta.encoder.layer.0.attention.self.query.loras.rotten_tomatoes.lora_A'\n",
    "name = re.sub(r'\\.(\\d+)', r'[\\1]', name)\n",
    "weights = torch.rand(32, 768)\n",
    "exec('model.'+name+'= Parameter(data=weights, requires_grad=True)')\n",
    "name='roberta.encoder.layer.0.attention.self.query.loras.rotten_tomatoes.lora_B'\n",
    "name = re.sub(r'\\.(\\d+)', r'[\\1]', name)\n",
    "weights = torch.rand(768, 32)\n",
    "exec('model.'+name+'= Parameter(data=weights, requires_grad=True)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13061\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training epoch 1: 100%|██████████| 534/534 [00:23<00:00, 23.16batch/s]\n"
     ]
    }
   ],
   "source": [
    "train_epoch(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
